{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c47cc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d5b61cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ INICIANDO PIPELINE DE MEJORA...\n",
      "\n",
      "==================================================\n",
      "1. DIAGN√ìSTICO INICIAL\n",
      "==================================================\n",
      "üìä Balanceo: 47.05%\n",
      "Distribuci√≥n target:\n",
      "target_variable\n",
      "0    19009\n",
      "1    16890\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üîó Top 5 correlaciones con target:\n",
      "target_variable      1.000000\n",
      "cust_hitrate         0.280532\n",
      "opp_old              0.172064\n",
      "cust_interactions    0.106199\n",
      "cust_contracts       0.089844\n",
      "cust_in_iberia       0.080362\n",
      "Name: target_variable, dtype: float64\n",
      "üéØ Baseline F1: 0.832\n",
      "\n",
      "==================================================\n",
      "2. FEATURE ENGINEERING\n",
      "==================================================\n",
      "‚úÖ Features creados. Total: 22 variables\n",
      "\n",
      "==================================================\n",
      "3. BALANCEO DE CLASES\n",
      "==================================================\n",
      "‚öñÔ∏è Desbalanceo m√≠nimo, no se aplica balanceo\n",
      "üìä Conjunto de entrenamiento: (28719, 22)\n",
      "üìä Conjunto de test: (7180, 22)\n",
      "\n",
      "==================================================\n",
      "4. ENTRENAMIENTO DEL MODELO\n",
      "==================================================\n",
      "üéØ XGBoost optimizado - F1 CV: 0.753 (+/- 0.007)\n",
      "\n",
      "==================================================\n",
      "5. EVALUACI√ìN FINAL\n",
      "==================================================\n",
      "üéØ F1-score MEJORADO: 0.767\n",
      "üìà Comparaci√≥n: 0.71 (anterior) ‚Üí 0.767 (nuevo)\n",
      "üí™ Mejora: +8.0%\n",
      "\n",
      "üìã Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.74      0.77      3802\n",
      "           1       0.74      0.80      0.77      3378\n",
      "\n",
      "    accuracy                           0.77      7180\n",
      "   macro avg       0.77      0.77      0.77      7180\n",
      "weighted avg       0.77      0.77      0.77      7180\n",
      "\n",
      "\n",
      "==================================================\n",
      "6. IMPORTANCIA DE VARIABLES\n",
      "==================================================\n",
      "Top 10 features m√°s importantes:\n",
      "                       feature  importance\n",
      "10                     opp_old    0.261632\n",
      "6                 cust_hitrate    0.074264\n",
      "15           eficiencia_ventas    0.062434\n",
      "16               valor_cliente    0.046072\n",
      "19      intensidad_competencia    0.042640\n",
      "11                competitor_Z    0.038989\n",
      "7            cust_interactions    0.038037\n",
      "1   product_B_sold_in_the_past    0.037879\n",
      "2        product_A_recommended    0.037731\n",
      "0   product_A_sold_in_the_past    0.036616\n",
      "\n",
      "üéâ PIPELINE COMPLETADO!üéâ\n"
     ]
    }
   ],
   "source": [
    "# 1. FUNCI√ìN DE DIAGN√ìSTICO\n",
    "def diagnostico_rapido(df, target='target_variable'):\n",
    "    # 1. Check desbalanceo\n",
    "    y = df[target]\n",
    "    balance_ratio = y.value_counts().min() / len(y)\n",
    "    print(f\"üìä Balanceo: {balance_ratio:.2%}\")\n",
    "    print(f\"Distribuci√≥n target:\\n{y.value_counts()}\")\n",
    "    \n",
    "    # 2. Check correlaciones con target\n",
    "    correlations = df.corr()[target].abs().sort_values(ascending=False)\n",
    "    print(f\"\\nüîó Top 5 correlaciones con target:\")\n",
    "    print(correlations.head(6))\n",
    "    \n",
    "    # 3. Modelo baseline r√°pido\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    X = df.drop(columns=[target, 'id'] if 'id' in df.columns else [target])\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    scores = cross_val_score(rf, X, y, cv=5, scoring='f1')\n",
    "    print(f\"üéØ Baseline F1: {scores.mean():.3f}\")\n",
    "    \n",
    "    return balance_ratio < 0.3, correlations\n",
    "\n",
    "# 2. FEATURE ENGINEERING ESPEC√çFICO\n",
    "def features_especificos_ventas(df):\n",
    "    X = df.copy()\n",
    "    \n",
    "    # Eliminar columnas que no son features\n",
    "    if 'target_variable' in X.columns:\n",
    "        X = X.drop('target_variable', axis=1)\n",
    "    if 'id' in X.columns:\n",
    "        X = X.drop('id', axis=1)\n",
    "    \n",
    "    # 1. RATIOS CLAVE\n",
    "    X['eficiencia_ventas'] = X['cust_hitrate'] / (X['cust_interactions'] + 1)\n",
    "    X['valor_cliente'] = X['cust_contracts'] * X['cust_hitrate']\n",
    "    \n",
    "    # 2. INTERACCIONES PRODUCTO-CLIENTE\n",
    "    X['product_A_affinity'] = X['product_A_sold_in_the_past'] * X['cust_hitrate']\n",
    "    X['product_B_affinity'] = X['product_B_sold_in_the_past'] * X['cust_interactions']\n",
    "    \n",
    "    # 3. COMPETENCIA AGREGADA\n",
    "    competitor_cols = [col for col in X.columns if 'competitor' in col]\n",
    "    if competitor_cols:\n",
    "        X['intensidad_competencia'] = X[competitor_cols].sum(axis=1)\n",
    "        X['mercado_competitivo'] = (X['intensidad_competencia'] > 1).astype(int)\n",
    "    \n",
    "    # 4. ESTACIONALIDAD MEJORADA\n",
    "    if 'opp_month' in X.columns:\n",
    "        X['es_fin_mes'] = (X['opp_month'] > 0.5).astype(int)\n",
    "    \n",
    "    print(f\"‚úÖ Features creados. Total: {X.shape[1]} variables\")\n",
    "    return X\n",
    "\n",
    "# 3. BALANCEO INTELIGENTE\n",
    "def balanceo_inteligente(X, y):\n",
    "    # Solo si hay desbalanceo significativo\n",
    "    if y.value_counts().min() / len(y) < 0.3:\n",
    "        smote = SMOTE(random_state=42, k_neighbors=3)\n",
    "        X_bal, y_bal = smote.fit_resample(X, y)\n",
    "        print(\"‚úÖ Datos balanceados con SMOTE\")\n",
    "        return X_bal, y_bal\n",
    "    else:\n",
    "        print(\"‚öñÔ∏è Desbalanceo m√≠nimo, no se aplica balanceo\")\n",
    "        return X, y\n",
    "\n",
    "# 4. OPTIMIZACI√ìN R√ÅPIDA\n",
    "def optimizacion_rapida(X, y):\n",
    "    # XGBoost con par√°metros b√°sicos optimizados\n",
    "    xgb_opt = XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        scale_pos_weight=len(y[y==0])/len(y[y==1]) if len(y[y==1]) > 0 else 1\n",
    "    )\n",
    "    \n",
    "    # Cross-validation\n",
    "    scores = cross_val_score(xgb_opt, X, y, cv=5, scoring='f1')\n",
    "    print(f\"üéØ XGBoost optimizado - F1 CV: {scores.mean():.3f} (+/- {scores.std():.3f})\")\n",
    "    \n",
    "    # Entrenar modelo final\n",
    "    xgb_opt.fit(X, y)\n",
    "    return xgb_opt\n",
    "\n",
    "# 5. PIPELINE MEJORADO COMPLETO\n",
    "def pipeline_mejorado_f1(df):\n",
    "    print(\"üöÄ INICIANDO PIPELINE DE MEJORA...\")\n",
    "    \n",
    "    # 1. DIAGN√ìSTICO\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"1. DIAGN√ìSTICO INICIAL\")\n",
    "    print(\"=\"*50)\n",
    "    needs_balance, top_correlations = diagnostico_rapido(df)\n",
    "    \n",
    "    # 2. FEATURE ENGINEERING\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"2. FEATURE ENGINEERING\")\n",
    "    print(\"=\"*50)\n",
    "    X_mejorado = features_especificos_ventas(df)\n",
    "    y = df['target_variable']\n",
    "    \n",
    "    # 3. BALANCEO\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"3. BALANCEO DE CLASES\")\n",
    "    print(\"=\"*50)\n",
    "    X_bal, y_bal = balanceo_inteligente(X_mejorado, y)\n",
    "    \n",
    "    # 4. DIVISI√ìN TRAIN/TEST\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_bal, y_bal, test_size=0.2, random_state=42, stratify=y_bal\n",
    "    )\n",
    "    \n",
    "    print(f\"üìä Conjunto de entrenamiento: {X_train.shape}\")\n",
    "    print(f\"üìä Conjunto de test: {X_test.shape}\")\n",
    "    \n",
    "    # 5. MODELO OPTIMIZADO\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"4. ENTRENAMIENTO DEL MODELO\")\n",
    "    print(\"=\"*50)\n",
    "    modelo_final = optimizacion_rapida(X_train, y_train)\n",
    "    \n",
    "    # 6. EVALUACI√ìN FINAL\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"5. EVALUACI√ìN FINAL\")\n",
    "    print(\"=\"*50)\n",
    "    y_pred = modelo_final.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"üéØ F1-score MEJORADO: {f1:.3f}\")\n",
    "    print(f\"üìà Comparaci√≥n: 0.71 (anterior) ‚Üí {f1:.3f} (nuevo)\")\n",
    "    print(f\"üí™ Mejora: {(f1 - 0.71) / 0.71 * 100:+.1f}%\")\n",
    "    \n",
    "    print(\"\\nüìã Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # 7. IMPORTANCIA DE FEATURES\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"6. IMPORTANCIA DE VARIABLES\")\n",
    "    print(\"=\"*50)\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X_mejorado.columns,\n",
    "        'importance': modelo_final.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"Top 10 features m√°s importantes:\")\n",
    "    print(feature_importance.head(10))\n",
    "    \n",
    "    return modelo_final, X_mejorado\n",
    "\n",
    "# USO FINAL\n",
    "if __name__ == \"__main__\":\n",
    "    # Cargar tus datos (ajusta la ruta)\n",
    "    df = pd.read_csv('dataset.csv')  # Cambia por tu ruta real\n",
    "    \n",
    "    # Ejecutar pipeline completo\n",
    "    modelo_final, features_mejorados = pipeline_mejorado_f1(df)\n",
    "    \n",
    "    print(\"\\n\" + \"üéâ PIPELINE COMPLETADO!\" + \"üéâ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
